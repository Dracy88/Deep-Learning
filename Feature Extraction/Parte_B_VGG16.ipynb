{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgPUg_26aoyi",
    "colab_type": "text"
   },
   "source": [
    "# Project AML\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Parte B: Feature Extraction based on VGG16 + SVM for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SLyKKSalGvJ",
    "colab_type": "text"
   },
   "source": [
    "## Google Colab Setting\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paruytRNarRj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Fix seed for reproducibility \"\"\"\n",
    "import numpy\n",
    "seed = 42\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5qi7wEB1au-r",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Access to Drive directory \"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qKFE0X1l0WX",
    "colab_type": "text"
   },
   "source": [
    "## Import Library\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNAWJLdGawzS",
    "colab_type": "code",
    "outputId": "f27f6398-7d1c-4571-f99b-d34fa7d555a3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Library \"\"\"\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications  \n",
    "from keras.models import Model \n",
    "from sklearn.svm import SVC\n",
    "from pyGPGO.covfunc import squaredExponential\n",
    "from pyGPGO.acquisition import Acquisition\n",
    "from pyGPGO.surrogates.RandomForest import RandomForest\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyCA03VLbGtS",
    "colab_type": "text"
   },
   "source": [
    "# A) Pre-Processing Part\n",
    "\n",
    "---\n",
    "In questa sezione vengono definite le funzioni per:\n",
    "\n",
    "- Eseguire la data augmentation sui dati di training\n",
    "- Estrarre le feature utilizzando la tecnica del Transfer Learning chiamata Feature Extraction\n",
    "- Suddividire le feature estratte in modalità supervisionato, ovvero Data e Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "YitwCkGBcQj7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def train_data(path):\n",
    "    \n",
    "    \"\"\" This function made:\n",
    "    - data augmentation on training data\n",
    "    - feature extraction based on pre-trained model\n",
    "    - split data in data and label\n",
    "    \"\"\"\n",
    "\n",
    "    ''' Data '''\n",
    "    generator_data = ImageDataGenerator(\n",
    "        rescale=1. / 255,  # Normalizing all channels [0-1]\n",
    "        rotation_range=30,  # Random rotation up to 45° (both verseses) \n",
    "        height_shift_range=0.1,  # Random vertically translation (up or down) up to 20%\n",
    "        width_shift_range=0.1,  # Random horizontally translation (left or right) up to 20%\n",
    "        horizontal_flip=True,  # Random mirroring of the image\n",
    "        brightness_range=(0.1, 1.2),  # Random brigthening of the image\n",
    "        fill_mode='wrap')  # Fill the images copying the nearest pixel\n",
    "\n",
    "    data_train_generator = generator_data.flow_from_directory(path,\n",
    "                                                              target_size=(224, 224),\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode=None,\n",
    "                                                              shuffle=False)\n",
    "\n",
    "    nb_train_samples = len(data_train_generator.filenames)\n",
    "\n",
    "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "\n",
    "    train_data = model.predict_generator(data_train_generator, predict_size_train)\n",
    "\n",
    "    print('training data created')\n",
    "\n",
    "    ''' Label'''\n",
    "    generator_label = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    label_train_generator = generator_label.flow_from_directory(path,\n",
    "                                                                target_size=(224, 224),\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                class_mode='categorical',\n",
    "                                                                shuffle=False)\n",
    "\n",
    "    train_labels = label_train_generator.classes\n",
    "\n",
    "    print('training label created')\n",
    "\n",
    "    return train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mJhpyEEscSgr",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def validation_data(path):\n",
    "\n",
    "    \"\"\" This function made:\n",
    "    - feature extraction based on pre-trained model\n",
    "    - split data in data and label\n",
    "    \"\"\"\n",
    "\n",
    "    ''' Data '''\n",
    "    generator_data = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    data_validation_generator = generator_data.flow_from_directory(path,\n",
    "                                                                   target_size=(224, 224),\n",
    "                                                                   batch_size=batch_size,\n",
    "                                                                   class_mode=None,\n",
    "                                                                   shuffle=False)\n",
    "\n",
    "    nb_validation_samples = len(data_validation_generator.filenames)\n",
    "\n",
    "    predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "\n",
    "    validation_data = model.predict_generator(data_validation_generator, predict_size_validation)\n",
    "\n",
    "    print('validation data created')\n",
    "\n",
    "    ''' Label'''\n",
    "    generator_label = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    label_validation_generator = generator_label.flow_from_directory(path,\n",
    "                                                                     target_size=(224, 224),\n",
    "                                                                     batch_size=batch_size,\n",
    "                                                                     class_mode='categorical',\n",
    "                                                                     shuffle=False)\n",
    "\n",
    "    validation_labels = label_validation_generator.classes\n",
    "\n",
    "    print('validation label created')\n",
    "\n",
    "    return validation_data, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "jNp--0yFjI4M",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def test_data(path):\n",
    "  \n",
    "    \"\"\" This function made:\n",
    "    - feature extraction based on pre-trained model\n",
    "    - split data in data and label\n",
    "    \"\"\"\n",
    "     \n",
    "    ''' Data '''\n",
    "    generator_data = ImageDataGenerator(rescale=1. / 255)\n",
    "  \n",
    "    data_test_generator = generator_data.flow_from_directory(path, \n",
    "                                                             target_size=(224, 224),\n",
    "                                                             batch_size=batch_size, \n",
    "                                                             class_mode=None, \n",
    "                                                             shuffle=False)\n",
    "\n",
    "    nb_test_samples = len(data_test_generator.filenames)  \n",
    "   \n",
    "    predict_size_test = int(math.ceil(nb_test_samples / batch_size))  \n",
    "  \n",
    "    test_data = model.predict_generator(data_test_generator, predict_size_test)  \n",
    "  \n",
    "    print('test data created')\n",
    "  \n",
    "    ''' Label'''\n",
    "    generator_label = ImageDataGenerator(rescale=1. / 255)\n",
    "  \n",
    "    label_test_generator = generator_label.flow_from_directory(path,\n",
    "                                                               target_size=(224, 224),\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               class_mode='categorical',\n",
    "                                                               shuffle=False) \n",
    "  \n",
    "    test_labels = label_test_generator.classes  \n",
    "    \n",
    "    print('test label created')\n",
    "\n",
    "    return test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQGBcrGqkVNj",
    "colab_type": "text"
   },
   "source": [
    "# B) Model Part\n",
    "\n",
    "---\n",
    "Viene importato un modello pre-trained presente su keras, ovvero VGG16 e vengono successivamente eliminati i layer da non utilizzare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "eDW2YQfIog8_",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "  \n",
    "    \"\"\"\n",
    "    This function\n",
    "      - import model and weight of pretained network\n",
    "      - define structure of network\n",
    "      - print summary of network\n",
    "    \"\"\"\n",
    "      \n",
    "    base_model = applications.VGG16(include_top=True, weights='imagenet')\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aiV_Li-NaQNA",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def objective(C, gamma):\n",
    " \n",
    "    \"\"\"\n",
    "    This function define SVM and hyper-parameter to optimize\n",
    "\n",
    "    :param C: Penality Parameter of the error term\n",
    "    :param gamma: kernel coefficient\n",
    "\n",
    "    :return: Score of validation data\n",
    "    \"\"\"\n",
    "\n",
    "    ''' Define SVM '''\n",
    "    svm_model_linear = SVC(kernel='rbf', C=C, gamma=gamma).fit(x_train, y_train)\n",
    "\n",
    "    ''' Evaluate SVM on Validation data '''\n",
    "    score = svm_model_linear.score(x_validation, y_validation)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huG0Fc0uc5hx",
    "colab_type": "text"
   },
   "source": [
    "# C) Ottimizzazione con SMBO\n",
    "\n",
    "Viene definita la fase di ottimizzazione bayesiana.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Pim4xie8yG_C",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def SMBO(model, acquisition):\n",
    "\n",
    "    \"\"\"\n",
    "    Define SMBO procedure for obtain best hyper-parameter\n",
    "\n",
    "    :param model: Surrogate Model\n",
    "    :param acquisition: Acquisition function\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ''' Start time '''\n",
    "    start_time = time.time()\n",
    "\n",
    "    ''' Define parameter range to evaluate '''\n",
    "    param = {'C': ('cont', [0.1, 1000]), 'gamma': ('cont', [0.001, 1])}\n",
    "\n",
    "    ''' Define GPGO function '''\n",
    "    gpgo = GPGO(model, acquisition, objective, param, n_jobs=1)\n",
    "\n",
    "    ''' Run Evaluation GPGO '''\n",
    "    gpgo.run(max_iter=120, init_evals=80)\n",
    "\n",
    "    ''' Print total time '''\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    ''' Plot History of best seen'''\n",
    "    plt.plot(gpgo.history)\n",
    "    plt.title('Accuracy through iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.show()\n",
    "\n",
    "    print(gpgo.getResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNgw0PRvbTVX",
    "colab_type": "text"
   },
   "source": [
    "# Main\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "In questa fase viene eseguita:\n",
    "\n",
    "- La fase di Pre-processing\n",
    "- La fase di Modelling\n",
    "- La fase di ottimizzazione bayesiana.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "PTEz2WzDbsDM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# number of epochs to train top model  \n",
    "epochs = 30  \n",
    "  \n",
    "# batch size used by flow_from_directory and predict_generator \n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8ycrBriHcQ5P",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" path in drive \"\"\"\n",
    "path_train = '/content/gdrive/My Drive/Colab Notebooks/PROJECT_AML/Dataset/TrainingSet/'\n",
    "path_validation = '/content/gdrive/My Drive/Colab Notebooks/PROJECT_AML/Dataset/ValidationSet/'\n",
    "path_test = '/content/gdrive/My Drive/Colab Notebooks/PROJECT_AML/Dataset/TestSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aM9GfqJjhtqV",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Import model \"\"\"\n",
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1PSuYZbNcYAe",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Create training data \"\"\"\n",
    "x_train, y_train = train_data(path_train)\n",
    "\n",
    "\"\"\" Save Training data \"\"\"\n",
    "np.save('x_train.npy', x_train)\n",
    "np.save('y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3-e5Ibvyc0jm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Create validation data \"\"\"\n",
    "x_validation, y_validation = validation_data(path_validation)\n",
    "\n",
    "\"\"\" Save Validation data \"\"\"\n",
    "np.save('x_validation.npy', x_validation)\n",
    "np.save('y_validation.npy', y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "w3roFJUkdpIS",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Create test data \"\"\"\n",
    "x_test, y_test = test_data(path_test)\n",
    "\n",
    "\"\"\" Save test data \"\"\"\n",
    "np.save('x_test.npy', x_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83cwQzp_d9V0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" When want import feature from .npy file \"\"\"\n",
    "\n",
    "\"\"\" Import training data \"\"\"\n",
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "\n",
    "\"\"\" Import validation data \"\"\"\n",
    "x_validation = np.load('x_validation.npy')\n",
    "y_validation = np.load('y_validation.npy')\n",
    "\n",
    "\"\"\" Import test data \"\"\"\n",
    "x_test = np.load('x_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "jrZiph1KmUsu",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Manual Tuning \"\"\"\n",
    "C = 200\n",
    "gamma = 0.001\n",
    "svm_model_linear = SVC(kernel='rbf', C=C, gamma=gamma).fit(x_train, y_train)\n",
    "score = svm_model_linear.score(x_validation, y_validation)\n",
    "score1 = svm_model_linear.score(x_test, y_test)\n",
    "print('Accuracy on validation', score)\n",
    "print('Accuracy on Testing', score1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Parte B - VGG16",
   "version": "0.3.2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
