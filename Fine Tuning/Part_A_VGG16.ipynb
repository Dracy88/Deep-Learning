{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE249M260ctm",
    "colab_type": "text"
   },
   "source": [
    "# **Project AML**\n",
    "\n",
    "# **Parte A:** Fine tuning based on VGG16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUDJx16HqnDy",
    "colab_type": "text"
   },
   "source": [
    "<h2>1. Importing Library</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GGN40YQW5O7w",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "N4VxicdI0otr",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' Fix seed for reproducibility '''\n",
    "seed = 42\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4EeaCeeh1GY9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' Access to Drive directory '''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-F8KgZ62gsA",
    "colab_type": "text"
   },
   "source": [
    "<h2>2. Pre-Processing: Data Augmentation</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "YF0ZtFzV24mp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# THIS IS GENERAL FUNCTION FOR DATA AUGMENTATION, WITHOUT ARGOMENT OF IMAGEDATAGENERATOR..\n",
    "\n",
    "def data_augmentation(path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function make data augmentation and generate data from directory, only for training.\n",
    "\n",
    "    :param path: is path of train\n",
    "\n",
    "    :return: data generated from directory\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ''' TO DO ARGOMENTI PER DATA AUGMENTATION'''\n",
    "    generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    data = generator.flow_from_directory(path,\n",
    "                                         target_size=(224, 224),\n",
    "                                         batch_size=32,\n",
    "                                         class_mode='categorical',\n",
    "                                         shuffle=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# THIS IS REAL FUNCTION FOR DATA AUGMENTATION, WITH ARGOMENT OF IMAGEDATAGENERATOR\n",
    "  \n",
    "\n",
    "def data_augmentation1(path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function make data augmentation and generate data from directory, only for training.\n",
    "\n",
    "    :param path: is path of train\n",
    "\n",
    "    :return: data generated from directory\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ''' TO DO ARGOMENTI PER DATA AUGMENTATION'''\n",
    "    generator = ImageDataGenerator(\n",
    "                    rescale=1./255, # Normalizing all channels [0-1]\n",
    "                    rotation_range=30, # Random rotation up to 45° (both verseses) \n",
    "                    height_shift_range=0.2, # Random vertically translation (up or down) up to 20%\n",
    "                    width_shift_range=0.2, # Random horizontally translation (left or right) up to 20%\n",
    "                    horizontal_flip=True, # Random mirroring of the image\n",
    "                    brightness_range=(0.1, 1.2), # Random brigthening of the image\n",
    "                    fill_mode='wrap') # Fill the images copying the nearest pixel\n",
    "    \n",
    "    data = generator.flow_from_directory(path,\n",
    "                                         target_size=(224, 224),\n",
    "                                         batch_size=32,\n",
    "                                         class_mode='categorical',\n",
    "                                         shuffle=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_generator(path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function generate data from directory\n",
    "\n",
    "    :param path: is path of data\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    generator = ImageDataGenerator(rescale=1. / 255)\n",
    "    data = generator.flow_from_directory(path,\n",
    "                                         target_size=(224, 224),\n",
    "                                         batch_size=32,\n",
    "                                         class_mode='categorical',\n",
    "                                         shuffle=False)\n",
    "    return data\n",
    "  \n",
    "  \n",
    "def test_generator(path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function generate data from directory\n",
    "\n",
    "    :param path: is path of data\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    generator = ImageDataGenerator(rescale=1. / 255)\n",
    "    data = generator.flow_from_directory(\n",
    "                          path, # target directory\n",
    "                          target_size=(224, 224), # all images will be resized to 224x224\n",
    "                          batch_size=1,\n",
    "                          #color_mode=\"rgb\",\n",
    "                          class_mode='categorical', # None, to return only the images.\n",
    "                          shuffle=False, # False, because we need to yield the images in “order”, to predict the outputs and match them with their unique filenames.\n",
    "                          seed=seed)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSkP988H4Cgv",
    "colab_type": "text"
   },
   "source": [
    "<h2>3. Modelling</h2>\n",
    "\n",
    "1) Import structure and weight of VGG16\n",
    "\n",
    "2) Edit structure of VGG16, delete some layer and add new.\n",
    "\n",
    "3) Define Training\n",
    "\n",
    "4) Define Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XGSX-VYJ360f",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def vgg16(weights_path=None):\n",
    "\n",
    "    \"\"\"\n",
    "    This function create structure of VGG16 and add weights\n",
    "\n",
    "    :param weights_path: path of weight of VGG16\n",
    "\n",
    "    :return: model with weights added\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_edit(path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function modify structure of VGG16 and add new layer.\n",
    "\n",
    "    :param path: path of weights\n",
    "\n",
    "    :return: new model modified\n",
    "    \"\"\"\n",
    "\n",
    "    model = vgg16(path)\n",
    "\n",
    "    # Freezing Vgg16 layer\n",
    "    for layer in model.layers[:32]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    \n",
    "    # number of layer to delete\n",
    "    number_delete_layer = 5\n",
    "\n",
    "    for i in range(number_delete_layer):\n",
    "        model.pop()\n",
    "\n",
    "    # Add new layers\n",
    "    model.add(Dense(2884, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1482, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(102, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def training(model, loss, optimizer, train, validation, epoch):\n",
    "\n",
    "    \"\"\"\n",
    "    This function compile model, training data, calculate execution time and plot result.\n",
    "\n",
    "    :param model: CNN model\n",
    "    :param loss: loss function\n",
    "    :param optimizer: optimizer function\n",
    "    :param train: train data\n",
    "    :param validation: validation data\n",
    "    :param epoch: epochs\n",
    "\n",
    "    :return: model trained on train data\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Start timer\n",
    "    time_start = datetime.datetime.now()\n",
    "\n",
    "    # Fit model\n",
    "    result = model.fit_generator(train, \n",
    "                                 validation_data=validation, \n",
    "                                 validation_steps=5, \n",
    "                                 steps_per_epoch=5,  \n",
    "                                 callbacks=[earlystopper, checkpointer],\n",
    "                                 #callbacks=[earlystopper],\n",
    "                                 epochs=epoch)\n",
    "\n",
    "    # Stop timer\n",
    "    time_stop = datetime.datetime.now()\n",
    "\n",
    "    # Print time\n",
    "    print(\"Execution time:\", (time_stop - time_start).total_seconds(), \"secondi\")\n",
    "    \n",
    "    print('Loss on train set:', round((result.history['loss'])[-1], 3))\n",
    "    print('Loss on validation set:', round((result.history['val_loss'])[-1], 3))\n",
    "    \n",
    "    print('Accuracy on train set:', round((result.history['acc'])[-1], 3))\n",
    "    print('Accuracy on validation set:', round((result.history['val_acc'])[-1], 3))\n",
    "\n",
    "    # Show Plot\n",
    "    show_history(result, 'acc', 'val_acc', 'accuracy', 'epoch', 'train', 'validation', 1, epoch)\n",
    "    show_history(result, 'loss', 'val_loss', 'loss', 'epoch', 'train', 'validation', None, epoch)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def show_history(result, measure1='', measure2='', metrics='', unit='', set1='', set2='', acc=None, epochs=100):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is util for plot history\n",
    "\n",
    "    :param result: contain result data\n",
    "    :param measure1: e.g. 'acc'\n",
    "    :param measure2: e.g. 'val_acc\n",
    "    :param metrics:  e.g. accuracy\n",
    "    :param unit: e.g. epoch\n",
    "    :param set1: e.g. training set\n",
    "    :param set2: e.g. validation set\n",
    "    :param epochs: e.g. number of epoch for plot\n",
    "    :param acc:\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    plt.plot(result.history[measure1])\n",
    "    plt.plot(result.history[measure2])\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0, epochs])\n",
    "    axes.set_ylim([0, acc])\n",
    "\n",
    "    plt.ylabel(metrics)\n",
    "    plt.xlabel(unit)\n",
    "    plt.legend([set1, set2], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def testing(model, test, batch):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function testing the test data and give in output the result\n",
    "    \n",
    "    :param model: model trained in training.\n",
    "    :param test: data to test\n",
    "    :param batch: dimension of batch\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    score = model.evaluate_generator(test, batch)\n",
    "\n",
    "    print(score[0], 'loss')\n",
    "    print(score[1], 'accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oletOSUF5WKf",
    "colab_type": "text"
   },
   "source": [
    "<h2>4. Experiment</h2>\n",
    "\n",
    "In this part:\n",
    "\n",
    "1) Define path of data\n",
    "\n",
    "2) Define Hyper-parameter\n",
    "\n",
    "3) Run Pre-processing Part\n",
    "\n",
    "4) Run Model Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-mqHb3095Qxs",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' path in drive '''\n",
    "path_train = '/content/gdrive/My Drive/Colab Notebooks/dataset/aml-project/TrainingSet/'\n",
    "path_validation = '/content/gdrive/My Drive/Colab Notebooks/dataset/aml-project/ValidationSet/'\n",
    "path_test = '/content/gdrive/My Drive/Colab Notebooks/dataset/aml-project/TestSet/'\n",
    "\n",
    "path_weights = '/content/gdrive/My Drive/Colab Notebooks/model/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "path_best_model = '/content/gdrive/My Drive/Colab Notebooks/output_file.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "qEb2mmuL7dUU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' Hyper-parameter '''\n",
    "batch_size = 32\n",
    "epochs = 300\n",
    "loss = 'categorical_crossentropy'\n",
    "lr = 0.00005\n",
    "decay = lr / epochs\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay, amsgrad=False)\n",
    "optimizer = adam\n",
    "\n",
    "checkpointer = ModelCheckpoint(monitor='val_loss', filepath='/content/gdrive/My Drive/Colab Notebooks/' + \"output_file\" + \".hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XGAerjSu7px0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' Pre-Processing'''\n",
    "train_generator = data_augmentation1(path_train)\n",
    "validation_generator = data_generator(path_validation)\n",
    "test_generator = test_generator(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "sLB8ePAi7s01",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' Structure of Model '''\n",
    "model = vgg16_edit(path_weights)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4WAUjyDX7vQX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' Training model'''\n",
    "training(model, loss, optimizer, train_generator, validation_generator, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Dec47hLv71Tl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "''' Testing model'''\n",
    "print(\"Testing\")\n",
    "time_start = datetime.datetime.now()\n",
    "#model.load_weights(path_best_model)\n",
    "\n",
    "# Fit model\n",
    "testing(model, test_generator, batch=6148)\n",
    "# Stop timer\n",
    "time_stop = datetime.datetime.now()\n",
    "\n",
    "# Print time\n",
    "print(\"Execution time:\", (time_stop - time_start).total_seconds(), \"secondi\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47CiL_9v1VlB",
    "colab_type": "text"
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Part_A_VGG16.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
